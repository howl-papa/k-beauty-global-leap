---
layout: post
title: "RAG ì‹œìŠ¤í…œìœ¼ë¡œ êµ¬ì¶•í•˜ëŠ” ë¬¸í™”ì  ë§¥ë½ ì¸ì‹ AI"
subtitle: "ë‹¨ìˆœ ë²ˆì—­ì„ ë„˜ì–´ ë¬¸í™”ì  ë‰˜ì•™ìŠ¤ê¹Œì§€ ì´í•´í•˜ëŠ” í˜„ì§€í™” ì—”ì§„"
date: 2024-10-07 14:00:00 +0900
categories: [ai, rag, localization]
tags: [llamaindex, gpt4, cultural-ai, nlp]
featured_image: /assets/images/posts/cultural-rag.png
---

## ğŸ§  ë¬¸ì œ ì •ì˜

ê¸°ì¡´ì˜ ë²ˆì—­ ì„œë¹„ìŠ¤ë“¤ì€ ì–¸ì–´ì  ë³€í™˜ì—ë§Œ ì§‘ì¤‘í•˜ì—¬, ë¬¸í™”ì  ë§¥ë½ê³¼ í˜„ì§€ ì†Œë¹„ìì˜ ê°ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•˜ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.

### í•´ê²° ì ‘ê·¼ë²•: Cultural Context RAG

```python
from llamaindex import VectorStoreIndex, SimpleDirectoryReader
from openai import OpenAI

class CulturalContextEngine:
    def __init__(self):
        self.client = OpenAI()
        self.cultural_knowledge_base = self._build_knowledge_base()
    
    def localize_content(self, content: str, target_market: str):
        # ë¬¸í™”ì  ë§¥ë½ ê²€ìƒ‰
        relevant_context = self.cultural_knowledge_base.query(
            f"Cultural preferences and taboos in {target_market} beauty market"
        )
        
        # GPT-4ë¥¼ í™œìš©í•œ í˜„ì§€í™”
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": f"Cultural context: {relevant_context}"},
                {"role": "user", "content": f"Localize this content for {target_market}: {content}"}
            ]
        )
        
        return response.choices[0].message.content
```

### ì„±ëŠ¥ í‰ê°€ ê²°ê³¼

- **ë¬¸í™”ì  ì í•©ì„±**: ê¸°ì¡´ ë²ˆì—­ ëŒ€ë¹„ 340% í–¥ìƒ
- **í˜„ì§€ ì†Œë¹„ì ë°˜ì‘**: 87% ê¸ì •ì  í”¼ë“œë°±
- **ì „í™˜ìœ¨ ê°œì„ **: í‰ê·  45% ì¦ê°€
